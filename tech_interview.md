<!-- markdown-toc start - Don't edit this section. Run M-x markdown-toc-refresh-toc -->
**Table of Contents**

- [数据结构（Data Structure）](#数据结构data-structure)
    - [HashMap](#hashmap)
    - [ConcurrentHashMap](#concurrenthashmap)
    - [SkipList 跳表](#skiplist-跳表)
    - [B+树](#b树)
- [操作系统（OS）](#操作系统os)
    - [进程和线程的区别](#进程和线程的区别)
    - [进程通信方式（IPC）](#进程通信方式ipc)
    - [虚拟内存](#虚拟内存)
    - [linux系统](#linux系统)
- [网络技术（Network）](#网络技术network)
    - [TCP 3次握手](#tcp-3次握手)
    - [TCP 4次挥手](#tcp-4次挥手)
    - [tcp和udp区别](#tcp和udp区别)
    - [TCP 流量控制](#tcp-流量控制)
    - [TCP 拥塞控制](#tcp-拥塞控制)
    - [HTTPS](#https)
    - [DNS使用的tcp还是udp](#dns使用的tcp还是udp)
    - [OSI七层模型](#osi七层模型)
- [JVM](#jvm)
    - [运行时数据区域](#运行时数据区域)
    - [GC算法](#gc算法)
    - [垃圾回收器](#垃圾回收器)
        - [CMS](#cms)
        - [G1](#g1)
    - [垃圾回收分区](#垃圾回收分区)
    - [类加载](#类加载)
    - [类加载器 ClassLoader](#类加载器-classloader)
- [并发 Concurrent](#并发-concurrent)
    - [volatile](#volatile)
    - [sychronized锁升级](#sychronized锁升级)
    - [一些锁](#一些锁)
        - [CAS](#cas)
        - [死锁](#死锁)
        - [AQS (TODO)](#aqs-todo)
    - [线程池](#线程池)
        - [线程池时核心参数](#线程池时核心参数)
        - [线程创建逻辑](#线程创建逻辑)
        - [拒绝策略](#拒绝策略)
        - [工作队列](#工作队列)
        - [几种线程池:](#几种线程池)
        - [线程池状态](#线程池状态)
    - [IO多路复用](#io多路复用)
- [数据库（Database）](#数据库database)
    - [事务的四个特性ACID](#事务的四个特性acid)
        - [MySQL 隔离级别](#mysql-隔离级别)
        - [事务隔离的实现（仅仅了解）](#事务隔离的实现仅仅了解)
    - [MySQL索引与最左匹配](#mysql索引与最左匹配)
    - [SQL（TODO）](#sqltodo)
    - [MySQL锁  （TODO）](#mysql锁--todo)
- [C++](#c)
    - [几种cast](#几种cast)
- [JAVA单独的问题](#java单独的问题)
- [Algorithm 算法](#algorithm-算法)
    - [大文件中的数据去重问题](#大文件中的数据去重问题)
- [Cloud computing](#cloud-computing)
    - [CAP定理](#cap定理)
    - [负载均衡算法](#负载均衡算法)
    - [http请求负载均衡的实现方式](#http请求负载均衡的实现方式)
    - [分布式锁](#分布式锁)
- [Redis](#redis)
    - [基本数据类型](#基本数据类型)
    - [同步](#同步)
    - [注意点](#注意点)
- [Hadoop](#hadoop)
    - [HDFS HA](#hdfs-ha)
    - [Hadoop写数据流程（TODO）](#hadoop写数据流程todo)
    - [ZooKeeper](#zookeeper)
        - [启动时的选举](#启动时的选举)
- [设计模式](#设计模式)
- [应用方向与其它](#应用方向与其它)
    - [设计一个秒杀系统](#设计一个秒杀系统)

<!-- markdown-toc end -->


相比java后台开发，大数据开发岗在数据库、web端的问题更少，多了些大数据开源库上的问题。

# 数据结构（Data Structure）

字节跳动的一个考法：有哪些容器类？

最好了解这些类的数据结构，List（LinkedList、ArrayList），Set（TreeSet、HashSet），Map（TreeMap、HashMap、LinkedHashMap）、Queue（PriorityQueue和LinkedList双端队列）、Stack。

不过一般大概率考HashMap和ConcurrentHashMap。

## HashMap

HashMap的实现大概率会考，看put函数源码了解hash+链表+红黑树就差不多。

比较偏的考点，将链表转红黑树的treefy阈值为什么是8，网上的说法主要是8的时候触发转红黑树的概率比较小，个人感觉这值是7是9对效率的影响也不大。

## ConcurrentHashMap

大体的逻辑和HashMap差不多，重点了解并发访问保证线程安全和效率的方式，大概是以Node为单位做更细粒度的加锁。

HashTable是直接在put上加的大锁，效率低一般不考虑。

## SkipList 跳表

在《算法导论》里并没有介绍，但由于某些方面的优点在Redis和HBase里使用了。

空间复杂度O(2n)，链表高度log n，每层查找最多3个元素，因此查找O(3log n)；插入过程和查找过程类似，由于链表插入时间复杂度为O(1)，因此最坏的在每级索引中都插入节点的情况也是O(log n)。删除过程和插入过程类似，同为O(log n)。

跳表并没有维护一个绝对均匀的索引，而是通过随机概率的形式保证上一级的索引的链表长度是当前级链表长度的一半。

优点：

1. 不用维护树的平衡，插入和删除过程更为高效，查询速度快
2. 区间查询速度快，缓存本地性强（相邻节点数据连续）
3. 实现简单（容易进行修改以添加新的功能）
4. 并发环境更友好（感觉不太存在，在修改最顶级索引链表时会锁住向下的搜索）

缺点：作为随机的数据结构，总是有产生最坏情况的可能。只拿性能和二叉搜索树比较并不合适，应该和randomly balanced binary search tree (RBST)比较更为合理。

Redis没有使用红黑树而是用跳表的原因同上： 1. 内存占用小 2. cache locality比树好（同时访问的数据会存储在相邻节点的可能性高） 3. 实现简单（添加新的功能修改更容易）。没有使用B+树，Redis重点是管理内存，B+树访问层数小带来的优势并不明显。

插入过程：以每向上一层概率下降1/2的公式生成一个随机数，得到当前节点的插入层数。从顶层向下查找，在需要插入的层中插入对应的节点，直到最底层的链表。

整体上插入、删除的过程都和查询过程类似，只不过在查询过程中进行了删除。

在博客上从来没有见过有同学讲述 HBase MemStore 的数据结构，其实 HBase MemStore 内部存储数据就使用的跳表。为什么呢？HBase 属于 LSM Tree 结构的数据库，LSM Tree 结构的数据库有个特点，实时写入的数据先写入到内存，内存达到阈值往磁盘 flush 的时候，会生成类似于 StoreFile 的有序文件，而跳表恰好就是天然有序的，所以在 flush 的时候效率很高，而且跳表查找、插入、删除性能都很高，这应该是 HBase MemStore 内部存储数据使用跳表的原因之一。HBase 使用的是 java.util.concurrent 下的 ConcurrentSkipListMap()。

Google 开源的 key/value 存储引擎 LevelDB 以及 Facebook 基于 LevelDB 优化的 RocksDB 都是 LSM Tree 结构的数据库，他们内部的 MemTable 都是使用了跳表这种数据结构。

作者：fanrui
链接：https://www.jianshu.com/p/9d8296562806
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

## B+树

通常作为数据库方向的题目。

主要用于和文件系统相关的索引，通过降低树的高度加快寻址，优点：

1. 高度低便于随机寻址
2. 范围查找可以直接按照叶子节点的方向读数据

最好顺便看一眼B树，两个对比。

# 操作系统（OS）

重点考进程与线程的区别，进程之前的通信方式，linux基础三点。偶尔可能碰到内存分页分段，极端情况有ext4文件系统，kafka一类的库可能会有page cache相关问题。

一般不太追问，作为八股文记就好。

## 进程和线程的区别

1. 拥有资源。进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
2. 调度。线程是CPU调度的基本单位，进程是操作系统分配资源的基本单位。
3. 系统开销。进程的创建和撤销因为要分配和回收内存、IO等更多的资源，因此开销比线程更大。
4. 通信方面。线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助IPC机制。

## 进程通信方式（IPC）

1、管道

管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据，管道一端的进程顺序的将数据写入缓冲区，另一端的进程则顺序的读出数据。只支持从一个进程到另一个进程的数据传输，只能用于具有亲缘关系的进程之间。

2、有名管道（FIFO）

主要为了解决管道没有名字，因此只能在有亲缘关系的进程之间通信的问题。
也称为命名管道，去除了管道只能在父子进程中使用的限制。

3、信号量

它是一个计数器，用于为多个进程提供对共享数据对象的访问。（比如一个信号变量的++和--）

linux内核中还有一种信号量用于锁机制的控制，和这个信号量不同。

4、消息队列

通过内存中存储的消息链表实现。相比于信号量能够表达的信息更多，也没有管道缓冲区大小受限制、没有具体类型、FIFO读取限制等问题，存放在内核。

5、共享内存

允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以速度快，但是考虑内存中数据修改时需要一定的锁机制控制访问。

通常用信号量和互斥锁来同步对共享存储的访问。

6、套接字

既可以用于不同机器间的进程通信，也可以用于单台机器内部的通信，在内部通信中内核进行了一定的实现提高socket效率，比如通过虚拟的lo网卡。

## 虚拟内存

虚拟内存的重点是将物理内存地址转变为逻辑内存地址给进程使用。

优势：1. 隔离各个进程，避免内存之间的相互访问；2. 通过内存分页、分段的形式，将不连续的内存空间对进程连续；3. 对物理内存和磁盘之间做映射。

分页机制。将物理内存按页划分，每次分配内存时分配空闲页对应的物理内存地址，通过映射的方式将程序访问的逻辑地址转换成页中的物理地址。

分段机制。将程序按照堆栈等方式分区。

段页式。将分段和分页结合，程序分段后使用分页机制管理。

## linux系统

常用命令:

- ls ps kill mkdir chmod df du
- 网络相关命令netstat（archlinux下改为了iproute2包中的ss）
- top等进程管理
- jstack等jvm相关性能工具

常见目录：etc,proc,usr等。

# 网络技术（Network）

网络技术大多只考三次握手四次挥手，稍微了解一下细节就差不多。java后台开发可能会考http等。

进一步想提现区分度可能会问TCP流量控制（阿里、快手）、Https流程、一次网页访问涉及的所有网络技术。

## TCP 3次握手

第一次：发送syn请求到服务器，并进入SYN_SENT状态，等待服务器确认。 SYN（Synchronize Sequence Number）
第二次：服务端收到syn请求，确认客户端的syn并返回ack应答；同时也发送一个syn包，服务器进入SYN_RECV状态。
第三次：客户端收到syn请求，确认后返回ack应答到服务器。

重点在于客户端和服务端协调唯一的isn（initial sequence number），为了避免延时、掉包等网络问题，syn请求可能会存在多次发送并带有不同的isn。TCP协议假设syn包的接收端无法确认在接收到带有不同isn的包时哪个包是真正想要的，只有发起端能判断哪些包是超时或者其它原因发送的。因此通过对所有的syn包回复ack发给syn包的发起端，让发起端发送RST（reset）指令拒绝所有不正常的ack应答。

## TCP 4次挥手

3次握手用于连接，4次挥手用于中断连接。

第一次：客户端数据发送完毕时，向服务端发送FIN包通知服务端停止，此时客户端无法发送数据。
第二次：服务端收到FIN请求后回复ack，并等待服务端的数据传输完。
第三次：服务端数据传输晚后发送FIN到客户端。
第四次：客户端确认服务端FIN请求并回复ack，等待2MSL的时候后释放资源（ack可能会丟，此时服务端会重发FIN）。服务端收到ack请求后释放资源。

## tcp和udp区别

https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md

- TCP面向连接，UDP是无连接的，即发送数据之前不需要建立连接。
- TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付。
- TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流，UDP是面向报文的，UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）
- 每一条TCP连接只能是点到点的，UDP支持一对一，一对多，多对一和多对多的交互通信。
- TCP首部开销20字节，UDP的首部开销小，只有8个字节。
- TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道。

TCP面向连接，提供可靠的服务，通过字节流，点对点，全双工。

UDP快、安全、支持一对多：首部小，拥塞不会导致主机发送速率降低。

## TCP 流量控制

解决的问题：发送方速度过快，接收方来不及接收，导致的分组丢失。

通过滑动窗口协议实现。tcp通过窗口为单位发送包，每个窗口内包含规定好数据量的TCP包。每次只有在收到一个窗口内包的ack应答后，才会发送下一个窗口的数据。TCP对于每一个发送的包，都会回复一个ack应答，ack应答包中包含了窗口大小信息和希望收到的下一个包的序号信息。通过这两个信息，发送方就可以判断下一次发送的包的数据位置。

对于发送端发送的一段数据，可以分成4部分：已经发送并得到对端ACK的、已经发送但还未收到对端ACK的、未发送但对端允许发送的、未发送且对端不允许发送、已经发送但还未收到对端ACK的、未发送但对端允许发送的。每次收到窗口对应的ack后会更新这几段的位置，并发送新的数据包。tcp通过窗口为单位发送包，每个窗口内包含规定好数据量的TCP包。每次只有在收到一个窗口内包的ack应答后，才会发送下一个窗口的数据。

## TCP 拥塞控制

网络的传输能力并非固定的，需要考虑网络的状态调整发送数据的速度，因此发送方维护了一个拥塞窗口来限制发送方的窗口大小。

刚建立连接时，通常使用慢启动的方式确定拥塞窗口的大小。将拥塞窗口分别设置为1、2、4、8逐步变大直到慢启动门限值。达到慢启动门限值后，线性的增大拥塞窗口。在这个过程中测试ack应答中是否存在超时。

当出现超时时，会将拥塞窗口和慢启动门限值都降低（其中慢启动门限设为拥塞窗口的一半，拥塞窗口设为1）。接收端可以发送三次重复ack应答，此时发送端会认为网络状况并非太差，而进入快速恢复机制，将拥塞窗口设置为之前的一半，慢启动门限值更新为拥塞窗口的大小，重新发送丢失的数据。

## HTTPS

向服务器建立TCP连接

1.客户端向服务端发送请求，客户端主要向服务器提供以下信息：支持的协议版本。支持的加密方法，比如RSA公钥加密。 支持的压缩方法。

2.服务器端收到请求后，向客户端做出回应，确认客户端发送的协议版本、加密方法等信息。 服务器证书。

3.客户端收到服务器回应以后，使用CA机构的公钥（浏览器中自带证书）验证服务器证书。然后，通过服务端的公钥加密用于通信的密钥（由客户端生成，用了前面几次通信时传输的随机数），传给服务端。

4.服务端对客户端加密过的秘钥进行解密，用得到的秘钥完成后续通信的加密。

## DNS使用的tcp还是udp

听说过没被问过。

直接进行域名解析使用的UDP，并且限制了传输报文的长度为一个包，这样可以通过发送一个包到DNS服务器，DNS服务器返回一个包，实现快速的数据回传。

DNS的辅助域名服务器向主域名服务器同步数据时，使用的TCP链接，由于同步过程涉及的数据量更大，相比稳定性不太需要考虑连接过程的开销。

为了保证域名解析中的安全问题，现在又加入了基于tls的域名解析。

## OSI七层模型

没怎么考过，估计是考起来不好追问没啥意思。

- 物理层:主要定义物理设备标准，这一层的数据叫做比特。
- 数据链路层:主要将从物理层接收的数据进行 MAC 地址(网卡的地址)的封装与解封装。常把这一层的数据叫做帧。在这一层工作的设备是交换机,数据通过交换机来传输。
- 网络层:主要将从下层接收到的数据进行 IP 地址(例 192.168.0.1)的封装与解封装。在这一层工作的设备是路由器,常把这一层的数据叫做数据包。
- 传输层:定义了一些传输数据的协议和端口号(WWW 端口 80 等),如:TCP(传输控制协议,传输效率低,可靠性强,用于传输可靠性要求高,数据量大的数据),UDP(用户数据报协议,与 TCP 特性恰恰相反,用于传输可靠性要求不高,数据量小的数据,如 QQ 聊天数据就是通过这种方式传输的)。 主要是将从下层接收的数据进行分段进行传输,到达目的地址后在进行重组。常常把这一层数据叫做段。
- 会话层:通过传输层(端口号:传输端口与接收端口)建立数据传输的通路。主要在你的系统之间发起会话或或者接受会话请求(设备之间需要互相认识可以是 IP 也可以是 MAC 或者是主机名)
- 表示层:主要是进行对接收的数据进行解释、加密与解密、压缩与解压缩等(也就是把计算机能够识别的东西转换成人能够能识别的东西(如图片、声音等))
- 应用层 主要是一些终端的应用,比如说 FTP(各种文件下载),WEB(IE 浏览),QQ 之类的(你就把它理解成我们在电脑屏幕上可以看到的东西.就 是终端应用)。

TCP/IP 协议分层

- 应用层
- 运输层（tcp、udp）
- 网络层（ip、ICMP、IGMP）
- 链路层（网络接口层）（ARP、RARP）

arp ：ip地址转mac


# JVM

GC算法和垃圾收集器（通常必考，可深可浅，最好知道优缺点，有些博客存在一定的误导）

内存分区、类加载机制相对少一点。

## 运行时数据区域

https://github.com/yuanguangxin/LeetCode/blob/master/Rocket.md

- Java虚拟机栈：每个方法在执行的同时都会创建一个栈帧 ，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。

- Java堆：对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。

- 方法区：方法区用于存储已被虚拟机加载的类信息、常量、静态变量，如static修饰的变量加载类的时候就被加载到方法区中。运行时常量池是方法区的一部分，class文件除了有类的字段、接口、方法等描述信息之外，还有常量池用于存放编译期间生成的各种字面量和符号引用。在老版jdk，方法区也被称为永久代。在1.8之后，由于永久代内存经常不够用或发生内存泄露，爆出异常java.lang.OutOfMemoryError，所以在1.8之后废弃永久代，引入元空间的概念。元空间是方法区的在HotSpot jvm 中的实现，元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。理论上取决于32位/64位系统可虚拟的内存大小。可见也不是无限制的，需要配置参数。

- 本地方法栈：虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。

- 程序计数器：程序计数器是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。是线程私有的内存。

JVM 内存区域主要分为线程私有区域【程序计数器、虚拟机栈、本地方法区】、线程共享区域【JAVA 堆、方法区】、直接内存。 线程私有数据区域生命周期与线程相同,。

可能的考点（没怎么碰到）：OutOfMemory和StackOverFlow的主要区别。

## GC算法

针对JVM堆，垃圾收集器的基本算法。

1、标记-清除算法。作为基础算法，首先标记所有需要清除的内存块，然后清除回收。效率低还容易造成内存碎片（CMS用这个回收老年代）。
2、标记-复制算法。将内存划分为两个区域，每次将一个区域存活的对象复制到另一个区域。简单高效但浪费空间。适用于回收后保留较少的新生代。
  新生代的回收通常使用这种算法，将Eden和survivor区存活的对象复制到另一个survivor。不过根据垃圾回收经验，新生代对象的回收率很高，eden和survivor分区没必要1:1。
3、标记-整理算法。标记可回收的对象，让这些对象占用的空间都向内存的一端移动，清理掉剩下的部分。对比标记复制，避免了空间的浪费，效率略低。

## 垃圾回收器

Stop the world原因，必须让线程都停在某一个点，避免标记垃圾碎片的过程中对象引用关系发生变化。

针对新生代，有单线程和多线程两种收集器，使用复制算法（新生代存活的对象不多）。

针对老年代，也是单线程和多线程收集器，使用标记整理或者标记清除算法。

CMS是针对老年代使用标记清除的收集器，通常配合新生代收集器使用。

G1内存划分相对比较特殊，没有直接的整体分代。把G1读为G one可能会有气势加成。

java12中出现了新的并发GC收集器，生产环境用得少一般不考。

### CMS

CMS（Concurrent Mark Sweep），并行的标记清除算法。针对老年代（通常配合Serial收集器和ParNew收集器），设计了一套尽可能停顿短的多线程回收机制。

CMS流程：1、初始标记，单线程，标记GC-root关联的对象，速度快；2、并发标记，多线程并发找所有需要标记的对象；3、重新标记，标记2过程中发生变化的部分；4、并发清除。其中1/3两步的标记过程需要Stop-the-world，每一步都需要等待线程运行到safe point或者safe region。

CMS缺点，总体上都是由于垃圾收集线程与用户线程并发导致：1、CMS对CPU资源非常敏感，并发标记与并发清除过程和其它进程同时运行，会抢占CPU资源。2、并发清理过程中用户线程在运行，可能产生浮动垃圾，并且需要预留能够使用的内存空间给用户线程。3、标记清除算法会产生大量碎片，导致老年代中的大对象无法分配内存触发full-gc。

新生代在晋升时老年代内存如果不够用（内存不够或者没有连续的内存），CMS会退化成单线程的Full GC（没有连续的内存会额外触发压缩）。

### G1

首先将内存划分为大小相等的区域，每个区域都可以是Eden、survivor、老年代、老年代巨型对象。

GC流程同CMS：1、初始标记；2、并发标记；3、最终标记；4、筛选回收。不同的是第4步的筛选回收使用的是并行而非并发，存在stop the world，也就是1、3、4都存在stop the world。

由于划分的分区粒度更小，在最后的筛选回收阶段会首先评估各个region的回收价值和成本并排序，然后根据用户期望的GC时间按顺序回收（ms级）。

分区粒度小并不意味着容易并发，由于分区之间很可能存在对象的引用，G1通过remenber set记录分区之间的引用信息。

## 垃圾回收分区

minor　GC和full GC的条件可能会用到，GC调优相关的问题可以结合这部分，加上GC日志。

jdk8 默认使用G1垃圾收集器，通常JVM将堆分成了两个大区Young和Old（新生代和老年代），而Young区分为 Eden、Servivor1、Servivor2已经不怎么合适了，按上面的G1的说法比较好。

Minor GC触发条件：当Eden区满时，触发Minor GC。

Full GC触发条件：
（1）调用System.gc时，系统建议执行Full GC，但是不必然执行
（2）老年代空间不足 （或将要不足，如下面的4 5）
（3）方法区空间不足 (??)

（4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存
（5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。

如果没有Survivor，Eden区每进行一次Minor GC，存活的对象就会被送到老年代
Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代

java内存调优：除了上面的各个分区的具体大小和比例可以设置，还可以限制jvm使用的总内存。

## 类加载

加载过程

- 加载。将类加载器得到的类二进制字节流加载到内存，按照虚拟机需要的格式存储在方法区，并生成java.lang.Class类的对象（hotspot把此对象放在方法区）。

- 验证。验证字节流信息符合当前虚拟机的要求，并确认是否安全。
 - 对于文件格式的验证，比如常量中是否有不被支持的常量？文件中是否有不规范的或者附加的其他信息？
 - 对于元数据的验证，比如该类是否继承了被final修饰的类？类中的字段，方法是否与父类冲突？是否出现了不合理的重载？
 - 对于字节码的验证，保证程序语义的合理性，比如要保证类型转换的合理性。
 - 对于符号引用的验证，比如校验符号引用中通过全限定名是否能够找到对应的类？校验符号引用中的访问性（private，public等）是否可被当前类访问？

- 准备。为类变量分配内存并设置变量类型对应的初始值，此处涉及的变量主要是存储在方法区静态变量，不包括实例化后放在堆中的实例变量。
 -  `public static int aa = 1;  // 此时会初始化为0， 赋值为1是初始化过程中类构造器处理的`

- 解析。将常量池的符号引用替换为直接引用，符号引用是用一组符号来描述所引用的目标与虚拟机实现的内存布局无关；直接引用是指向目标的指针，和内存布局相关。具体可以表达为将类名、方法名一类的字符串表达替换成对应的地址。

- 初始化。前面都是jvm对类的解析，这一步开始运行java的字节码，执行类的构造过程，主要是对类变量的赋值以及静态代码块的处理。
	
## 类加载器 ClassLoader

- 启动类加载器（bootstrap）：它负责加载<JAVA_HOME>/lib目录下的java核心库以及对应参数（-Xbootstrap）指定路径下的类库。开发者无法调用。
- 扩展类加载器：它负责加载<JAVA_HOME>/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用。
- 系统类加载器：用Java语言实现，它负责加载系统类路径ClassPath指定路径下的类库，开发者可以直接使用

类的加载方式：隐式加载（通过new）；显式加载（通过Class.forName）

动态加载的优势：

1. 通过自定义的类加载器，可以在运行时动态的从网络或其它地方获取的二进制流转换为代码。
2. 可以在运行时动态选择需要加载的类而非编译器。

加载器有一种双亲委派模型，收到类的加载请求时首先将讲求转发给父类加载器，相当于给不同位置的类设置了优先级，当同一类名的类出现在多个路径中时，首先加载上一层类加载器对应位置的类，优先保证程序的基础行为。


# 并发 Concurrent

必考重点，和应用相关而且对业务非常重要，主要考多线程、锁和线程池。

## volatile

两个特点：第一，标记的变量的修改会马上对其它的线程可见；第二，避免代码优化。

重点的考点，单例模式中如果单例的对象没有用volatile标记，可能会出现“无序写入”的问题。

在CPU处理变亮时，首先会从内存将变量读取到缓存中，而多线程并没有直接共享缓存，因此一个变量可能会存储在多个缓存中。这种情况可能会导致多线程访问时的不一致问题，如多个线程进行i++，当一个线程执行完还未将结果从缓存存到内存中时，另一个线程可能会从内存中获取先前的值，导致计算结果的冲突。

volatile关键字能够避免这种情况，修改后的值会从缓存写入内存中，并让其他对此变量的缓存值失效（缓存一致性协议）。保证一个线程的修改对其它的线程可见。

## sychronized锁升级

synchronized会先使用偏向锁，允许同一线程再次获取锁；如果有其它线程同时访问到锁，就升级为轻量级锁，通过CAS自适应自旋的方式，防止线程的挂起和切换；最后，如果自旋时间过长则升级为重量级锁。

synchronized会对加锁的代码段或者函数代码段添加monitorenter和monitorexit两个指令，当执行到monitorenter指令时会尝试获取对象的锁，

由于维护的难度较大，jdk15中Disable and Deprecate Biased Locking。通过偏向锁可以避免CAS的开销，但java5中新的并发数据结构效率更高，并且偏向锁的额外开销会影响使用线程池队列的效率（This means that applications that benefit from biased locking due to unnecessary synchronization will likely see a performance improvement if the code is updated to use these newer classes. Furthermore, applications built around a thread-pool queue and worker threads generally perform better with biased locking disabled）。一般不考。

## 一些锁

悲观锁，某个线程访问资源时，会拒绝其它线程访问资源。也成独占锁、互斥锁。如synchronized升级后的锁。

乐观锁，假设通常不会发声冲突，发生冲突时进行重试（不切换线程但占用CPU），主要用于锁等待时间不长一类的场景如读多写少。通常用CAS实现。

自旋锁。通常用乐观锁的CAS实现，当发生变亮被锁时不切换线程，而是先等待一段时间看锁是否被释放。用CPU开销避免线程切换的开销。

### CAS

java并发编程必考

CAS是乐观锁的一种实现方式，在修改某一个变量时，只能由一个线程修改。相对于Synchronize是一种更轻量级的锁，通常用来配合循环实现自旋锁。

首先取变量的值，在准备修改时，首先判断当前变量是否被其他线程修改过（通过compare看是否相等），如果没被修改则使用swap修改，如果修改则获取新的值重试。

要完成compare and swap操作，需要一定的CPU底层指令的优化支持，要保证compare后和swap之前不会被其它线程改变，因此CAS在出现较晚。

java CAS底层的实现调用了native实现的unsafe类，在CPU的底层对要访问的内存区域做了加锁，在原子操作中比较是否为先前的值，如果是则替换为新的值。

缺点：1、性能问题，使用自旋锁在线程多时可能会大量占用CPU资源；2、ABA问题，难以避免一个变量A被修改成另一个值B后又修改回A。

对于ABA问题，可以使用AtomicStampedReference，带时间戳的操作标记是否被修改过。

### 死锁

没被问过。

产生死锁必须具备以下四个条件：

- 互斥条件：该资源任意一个时刻只由一个线程占用。
- 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不剥夺条件: 线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
- 循环等待条件: 若干进程之间形成一种头尾相接的循环等待资源关系。

- 破坏互斥条件 ：这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。
- 破坏请求与保持条件 ：一次性申请所有的资源。
- 破坏不剥夺条件 ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
- 破坏循环等待条件 ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

### AQS (TODO)


## 线程池

new Thread弊端： 每次启动线程都需要new Thread新建对象与线程，性能差。线程池能重用存在的线程，减少对象创建、回收的开销。线程缺乏统一管理，可以无限制的新建线程，导致OOM。线程池可以控制可以创建、执行的最大并发线程数。缺少工程实践的一些高级的功能如定期执行、线程中断。线程池提供定期执行、并发数控制功能

### 线程池时核心参数

- corePoolSize：核心线程数量，线程池中应该常驻的线程数量
- maximumPoolSize：线程池允许的最大线程数，非核心线程在超时之后会被清除
- workQueue：工作队列，存储等待执行的任务
- keepAliveTime：线程没有任务执行时可以保持的时间
- unit：上面的存活时间单位
- threadFactory：线程工厂，来创建线程
- rejectHandler：当拒绝任务提交时的策略（抛异常、用调用者所在的线程执行任务、丢弃队列中第一个任务执行当前任务、直接丢弃任务）

### 线程创建逻辑

```java
if(核心线程数未满){
  创建核心线程；
} else {
  if(队列未满){
    加入队列等待；
  } else {
    if(线程池未满){
	  创建非核心线程；
	} else {
	  使用拒绝策略；
	}
  }
}
```

### 拒绝策略

- AbortPolicy(抛出一个异常，默认的)
- DiscardPolicy(直接丢弃任务)
- DiscardOldestPolicy（丢弃队列里最老的任务，将当前这个任务继续提交给线程池）
- CallerRunsPolicy（交给线程池调用所在的线程进行处理)

线程的异常处理：

1. 在线程代码内catch
2. Future.get()时catch
3. 工作线程设置UncaughtExceptionHandler
4. 继承ThreadPoolExecutor，重写ThreadPoolExecutor的afterExecute方法

### 工作队列

- ArrayBlockingQueue，用数组实现的有界队列
- LinkedBlockingQueue  用链表实现的无界队列（也可以设置具体的容量，默认为整型的最大）
- DelayQueue
- PriorityBlockingQueue 能够指定优先级
- SynchronousQueue（同步队列）一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQuene，newCachedThreadPool线程池使用了这个队列。（相当于没有队列，直接向线程池提交任务，当线程池满时会阻塞）

因此工作队列可以分为下面的几种：

- 直接提交。SynchronousQueue是一个没有数据缓冲的BlockingQueue，生产者线程对其的插入操作put必须等待消费者的移除操作take。将任务直接提交给线程而不保持它们。
- 无界队列。当使用无限的maximumPoolSizes时，将导致在所有corePoolSize线程都忙时新任务在队列中等待，容易导致OOM。
- 有界队列。当使用有限的maximumPoolSizes时，有界队列（如ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。
	
### 几种线程池:

- newFixedThreadPool(固定数目线程的线程池)，核心线程与最大线程相等，没有超时闲置会被删除的线程，因此超时参数为0，使用无界队列LinkedBlockingQueue<Runnable>。
- newCachedThreadPool(可缓存线程的线程池)，核心线程为0，最大线程数为Integer.MAX_VALUE，阻塞队列用的SychronousQueue，空闲存活时间为60s。每次提交新的任务都会创建新的线程，当提交任务的速度大于处理速度时，会由于线程数过多导致资源消耗过大。
- newSingleThreadExecutor(单线程的线程池)，核心线程和最大线程数都是1，阻塞队列用的LinkedBlockingQueue，keepAliveTime为0。用于大量短期任务和串行执行的任务。
- newScheduledThreadPool(定时及周期执行的线程池)，构造函数输入核心线程数，最大线程数Integer.MAX_VALUE，阻塞队列DelayedWorkQueue，可以设置按周期执行或者延时后执行。

面试题（快手）：为什么阿里的java开发手册不允许使用原生线程池？  其中使用的阻塞队列都没有限制长度，容易导致OOM。

### 线程池状态 

没怎么考过

- RUNNING。该状态的线程池会接收新任务，并处理阻塞队列中的任务;调用线程池的shutdown()方法，可以切换到SHUTDOWN状态;调用线程池的shutdownNow()方法，可以切换到STOP状态;
- SHUTDOWN。该状态的线程池不会接收新任务，但会处理阻塞队列中的任务；队列为空，并且线程池中执行的任务也为空,进入TIDYING状态;
- STOP。该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务；线程池中执行的任务为空,进入TIDYING状态;
- TIDYING。该状态表明所有的任务已经运行终止，记录的任务数量为0。terminated()执行完毕，进入TERMINATED状态。
- TERMINATED。该状态表示线程池彻底终止。

## IO多路复用

在NIO中和操作系统里都有，下面主要指NIO中实现非阻塞的socket通信。

select函数在没有收到数据时会直接阻塞进程，底层用数组实现，主要缺点在于后面要判断是那些socket收到数据需要遍历整个socket，因此限制了最大的socket数为1024。其次，每次调用select时需要将socket的集合从用户态拷贝到内核态。

poll与select的主要区别在于用链表实现，无最大的连接限制。仍存在遍历fd效率低，调用poll函数时需要从用户态拷贝到内核态的问题。

epoll使用hash表实现，解决了遍历效率低的问题。通过分离拷贝过程和等待过程，在epoll_ctl时进行一次从用户态到内核态的拷贝，后面的epoll_wait过程中不需要拷贝。

```java
while(1){
    int n = select(..., fds, ...)
    for(int i=0; i < fds.count; i++){
        if(FD_ISSET(fds[i], ...)){
            //fds[i]的数据处理
        }
    }
}
```

# 数据库（Database）

不撸SQL的话，不是考B+树就是ACID。有些会考锁。

## 事务的四个特性ACID

原子性（atomicity)  一个事务要么全部提交成功，要么全部失败回滚，不能只执行其中的一部分操作。重点强调事务操作只能够全部提交或者回滚。通常的一种执行方式是通过首先将数据复制到undo log，当出现错误或用户执行ROLLBACK时，利用undo log中的内容恢复数据。

一致性（consistency) 事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行之前和执行之后，数据库都必须处于一致性状态。这里一致性主要指数据库本身的状态约束（通过AID保证）和数据库用户对数据的约束（通过程序在执行完事务后 的检查保证），通常保证AID即可基本保证一致性。

隔离性（isolation） 事务的隔离性是指在并发环境中（如多用户），并发的事务时相互隔离的，一个事务的执行不能不被其他事务干扰。通过加锁解决不同事务对相同数据的访问问题， 在标准SQL规范中，定义了4个事务隔离级别，不同的隔离级别对事务的处理不同，分别是：未授权读取，授权读取，可重复读取和串行化。默认情况下一个事务在改变了某个数据但还未提交时，另一个事务访问该数据会得到改变前的值。

持久性（durability） 事务提交后，数据库中的状态改变就会永久保存到数据库中，也就是所有修改的记录要被持久化到硬盘。这个是通过redo log实现，数据的修改会先对内存中的数据操作，修改的日志通过append的方式写入硬盘，出现故障时从redo log中恢复数据。

### MySQL 隔离级别

SQL定义了4种类型的隔离级别，越高级别的隔离并发处理支持越难，系统开销越小。

Read Uncommited（读未提交）。所有事务都可以看到其它未提交事务当前的执行结果。很有可能读到一个事务未处理完的结果（脏读），很少使用。

Read Commited（读取提交内容）。主要解决上面的**脏读**问题，一个事务读到另一个事务修改的数据时，只有另一个事务在提交后才能得到修改的结果。可能会发生**不可重复读**（连续两次取某行数据时，可能由于另一个事务的修改得到两个不同的结果）和**幻读**（解释见下面）。

Repeatable Read（可重读）。MySQL默认的级别。解决上面的**不可重复读问题**，但仍存在**幻读**问题（连续两次查到的行数不一样）。

Serializable（可串行化）。最高的隔离级别，强制事务排序降低事务之间的影响。

备注：关于可重复读，一个事务运行时，不一定总是要获取最新的数据，如一个账单一直在变化，进行对账时如果每次都使用最新更改的数据可能会让多次select的结果对不上。因此，可重复读主要实现的是当一个事务开始执行时，每次select到的数据都是某一时间点的数据而非最新数据，不受其它事务的影响。

### 事务隔离的实现（仅仅了解）

对于每一行数据，MySQL存储时会额外存储最后修改的事务id以及指向修改前上一版本的回滚指针（多个版本形成版本链），事务在查询某一行数据时，能够获取到一个包含当前还未提交的事务id列表（ReadView），通过这一列表能够从版本链中找到已经生效的事务id对应的行数据。 当隔离级别为Repeatable Read时，能够获取到在第一次select时修改的事务列表，通过这一列表找到没有修改过数据的版本。 大体上看，也就是每次事务的修改并不会删除修改前的记录，而是添加了新的行并且行中还存储了对应的事务id（和undo log有关），因此通过修改过数据的事务id列表就能够获取修改前的数据。以上来自b站https://www.bilibili.com/video/BV1W64y1u761?p=7 某些细节和《高性能MySQL》并不一致，建议以下面来自书上的为准。

MVVC多版本并发控制，大多数的读操作都不用加锁，但是每行记录都用了额外的存储空间，需要更多的行检查。InnoDB中，MVVC只在Read commited和Repeatable Read两个隔离级别下有效。

Innodb的MVVC在每行记录后面添加了两个隐藏列，一个保存行版本号（用系统版本号），一个删除标记（也用系统版本号）。每开始一个新的事务，都会对系统版本号递增。在Repeatable Read的隔离级别下，InnoDB会从创建时间中找系统版本号小于等于当前系统版本号的行版本，确保读取的行是在当前事务执行前存在或者自身修改过的；并且保证行的删除时间未定义或系统版本号大于当前版本，确保读取的行在当前事务执行下未被删除。

对于Insert和delete，插入或删除一行并修改对应的行版本号或删除标记为当前的系统版本号。

对于UPDATE，会插入一行新记录，保存版本号为当前的系统版本号；并将向前的行中的删除标记更新为当前的系统版本号。

## MySQL索引与最左匹配

联合几列的索引如a、b、c三列的联合索引，在处理时相当于将对字符串abc排序。如111,121,122,211,311,312（假设abc各代表一个数）。底层的处理是直接将（a，b，c）作为一个集合进行索引排序，比较两个集合的大小时，先比较a的大小，如果a相等则比较b的大小...因此，单独看a时，在B+树上会按顺序排列；单独看b，在每个a相等的区间按顺序排列。

因此sql语句中，对于a、b、c三列的联合索引，只有左边的列限定了值（只能是=某个值或者In某几个值）：

- where a = 1 and c<2 会调用索引（a=1对应的索引区域是连续的区间，能够通过索引获得对应的值）
- where a>1 and c<2 只会用索引查a（a>1对应多个区间，再从多个区间中找c<2的区间效率并不高）。

MySQL用了一种遇到范围查询就不再对后面的查询用索引的机制。如上面的a>1，对后面的b、c的条件会不使用索引。

实战可参考  https://zhuanlan.zhihu.com/p/115778804

## SQL（TODO）

大数据岗没怎么考这个。

重点 Group By，Join

## MySQL锁  （TODO）

加锁对于select没有影响

读锁： 

- select ... lock in share model  S锁

写锁：

- DELETE INSERT UPDATE
- select ... for update   对查询到的行加锁，要求查询到的数据不能被其它的事务修改。只有指定主键才会锁行，否则会锁表。

事务commit或者rollback这种结束之后，锁会被取消。


# C++

就说了一句之前用过一段时间C++，字节上来就飙C++的面试题，玩不起。

## 几种cast

1，const_cast  用于移除const或volatile（多线程和硬件相关，避免优化造成的影响）

2，static_cast 用于基本类型的转换和类指针的转换，相当于此前的强制类型转换，但在编译期会做检查，如转换不相关的类会编译报错。

3，dynamic_cast 在运行时检查基类到派生类（B2D）以及派生类到基类（D2B）是否安全。要求基类里有至少一个虚函数。

其中，D2B的转换和static_cast类似。对于B2D的转换，当基类Base有多个派生类D1、D2时，基类指针pB可能指向D1或者D2的对象。当pB指向D1，dynamic_cast<D2>(pB)会返回NULL，由于D1的对象无法直接转给D2，static_cast在编译期的检查则无法完成这种cast。由于运行时检查用到了虚函数表，因此要求必须要要虚函数。

4，reinterpret_cast 用于不相关的类型转换。除了某些特殊场景一般用得少，如某些库（stackoverflow上提到vendor）将自定义的类强行转成库要求的类型。


# JAVA单独的问题

相对来讲java单独的问题不多，主要还是结合多线程、jvm一类的问题：

- java泛型的实现机制和优缺点
- java集合类
- 性能监视工具（大概率考）
- GC日志

# Algorithm 算法

## 大文件中的数据去重问题

非手撕算法里的常考。

方案一，hash分解。将大文件中的数据按hash%n分配到n个文件，n设置为足够大使每个划分后的文件能够放入内存。针对每个小文件，当出现hash分布不均匀时，可以再次划分。此时问题转变为在每个小文件中查找重复的记录，可以考虑直接HashSet判断是否重复。（一个常见的字符串处理方式）

方案二，位图（编程珠玑）。只限制在qq号，电话一类的数字或通过某种方式能够转变为唯一数字的数据。申请一个足够大的数组，每个值对应一个bit（可以考虑用更大的数据类型表示多位）。此时对于每一条数据，都可以在位图数组上添加一个标记，当发现位图数组中已经被标记过时，则当前数据为重复数据。（针对能用数字表达的数据非常高效）

方案三，外排序。文件分成多个块，分别排序，然后用归并排序思想多路归并得到整个排序结果。（时间复杂度比上面的明显高）


# Cloud computing

## CAP定理

CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者一般只能满足两个。

- 一致性（C, Consistency）：对某个指定的客户端来说，读操作能返回最新的写操作结果
- 可用性（A, Availability）：在合理的时间返回合理的响应（某些节点的故障不影响服务可用）
- 分区容错性（P，Partition Tolerance）：分区容错性是指当网络出现分区（两个节点之间无法连通）之后，系统能否继续履行职责
	
通常这三点里P是基础，由于当前的网络硬件肯定会出现延迟丢包等问题，所以考虑最差情况，分区容忍性是一般是需要实现的。一般权衡选择CP或者AP，当保证一致性C时，当由于网络错误或者节点宕机时，接收客户端到访问的节点有两个选择：1. 保证数据的一致性C，返回错误或超时；2. 保证可用性A，返回当前最新的数据。

典型的CP设计是ZooKeeper。为了保证一致性：当mater节点出现故障时，leader选举过程会不可用；在某些极端情况下，ZooKeeper可能会丢弃一些请求。

典型的CP设计还有MongDB、Redis、Hbase。其中HBase的每个region由一个RegionServer管理，数据必然保持一致；当被访问的RegionServer发生故障时，需要其它的节点恢复，此时会出现一段时间的不可用。

AP设计有Cassandra、CouchDB。

## 负载均衡算法

1、随机和加权随机。随机分配，如HDFS。
2、轮询和加权轮询。依次将请求分配到各个服务器。可以考虑根据硬件条件对不同服务器加权，优先分配给权重较高的服务器（每次得到请求后权重减去请求数）。如Nginx。缺点：要求每个请求消耗的资源类似；到达的结点不确定。
3、Hash和一致性Hash。

## http请求负载均衡的实现方式

1、http重定向。http请求返回304，然后重定向到另外一台服务器。会暴露所有服务器的ip，两次http请求的效率也偏低。
2、DNS负载均衡。在DNS中一个域名对应多个IP A记录的解析，实现简单，DNS服务器会以轮询的方式依次将DNS请求解析到各个IP。但是无法避免服务器宕机，不能却分服务器的差异，也无法隐藏内网ip。
3、反向代理。反向代理服务器将请求转发给其它服务器，如Nginx和Apache。仍工作在http层，基于反向代理的负载均衡也被称为7层负载均衡。
4、IP负载均衡。通过网络地址转换(NAT)，负载均衡服务器直接将ip修改成需要被转发的服务器ip，在服务器向负载均衡服务器返回结果后，负载均衡服务器修改目的ip为客户端。称为四层负载均衡。
5、直接路由。负载均衡服务器直接改mac地址，然后发给计算服务器，计算服务器将请求结果直接返回给客户端。（吞吐量最大的方法，大公司一般使用这种）

## 分布式锁

通常使用Redis或者ZooKeeper。

Redis，创建一个会过期的key，修改完数据后删除这个可以。设置会过期主要是避免当前服务宕机导致key一直存在redis中导致锁无法被删除。

ZooKeeper维护了一个保证一致性的目录，每个线程获取锁时在/lock目录下创建一个临时的有序结点。如果结点在当前目录是最小的（前面线程创建的结点都被删除），则认为获取锁成功。如果不是最小的，则对前一个结点加一个事件监听。


# Redis

只是简单笔记，考的时候直接说的不会了，常考。

## 基本数据类型

字符串String、字典Hash、列表List、集合Set、有序集合SortedSet。

## 同步

从服务器发送同步指令；主服务器将数据打包成rdb文件，发送给从服务器；主服务器将写缓冲区的数据发送给从服务器。

2.8版本之后，从服务器断线重连不需要重新执行完整的同步，而是可以用psync直接发送修改的数据。

## 注意点

避免大量的key在同一时间点过期，以免在某一个时间点的负载过高导致严重的卡顿。可以在过期时间上添加随机数。

分布式锁：set指令通过参数能够设置加锁和过期时间，避免setnx expire两条指令执行的非原子性。（执行完setnx后宕机会导致锁无法删除）

Redis是怎么持久化的？服务主从数据怎么交互的？

RDB做镜像全量持久化，AOF做增量持久化。因为RDB会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据。


# Hadoop

几乎必考的两个点：1. HA机制（脑裂的处理）；2. 写数据流程以及出现故障时的处理。
 
## HDFS HA

namenode存在单点故障，启动一个新的namenode需要的步骤：1.将命名空间的镜像导入内存中；2.重演编辑日志；3.接收到足够多的datanode的数据块后退出安全模式。通常在大规模集群中，冷启动需要30分钟甚至更长。

Hadoop默认使用了Zookeeper组件为基础的故障转移控制器（zkfc zookeeper failover controller），当检测到namenode出现问题时，会选举出一个新的namenode处于active状态。

当网络非常慢或者被分割时，可能会产生脑裂现象，旧的active namenode没有及时转为standby而继续相应请求。QJM在同一时间只允许一个namenode向编辑日志中写入数据，为了避免另一个namenode响应读请求，在新的active namenode检测到旧的namenode还处于active状态时，一般直接用ssh命令杀死namenode进程。

HA重点是active的namenode宕机时，更快的让standby namenode加载最新的HDFS元数据以及datanode的心跳数据。因此主要做了几种处理：1、用一组journal node组成的QJM存储edit log；2、datanode每次向所有的namenode发送数据块报告；3、客户端使用显示的处理namenode失效；4、standby namenode承担secondary namenode的任务周期性的创建check point。

1、主备namenode之间要有高可用的共享存储；有NFS和QJM（quorum journal manager群体日志管理器）两种形式。通常推荐QJM，通过一组journal node实现，每一次的编辑必须写入多个QJM。

2、datanode需要同时向两个namenode发送数据块报告；3、客户端使用特定的机制处理namenode的失效；4、备用Namenode为active namenode设置周期性检查。

## Hadoop写数据流程（TODO）

## ZooKeeper

https://www.cnblogs.com/jay-huaxiao/p/13599519.html

### 启动时的选举

每次投票都有一个推举的服务器id和一个当前投票编号的id,（id, ZXID）。数据越新，ZXID越大，启动时ZXID为0。

1、每个server都给自己投票，此时server1的投票为（1，0），server2为（2,0）
2、每个server接收其它服务器的投票，判断投票的有效性（如ZXID是否相同，是否来自LOOKING状态的服务器）
3、将别人的投票和自己的做对比，投ZXID更大的服务器，当ZXID相等时，投id更大的服务器。
4、当发现有半数的服务器被投票时，认为选出了leader，然后leader服务器变更状态为Leader，其它变更状态为Follower


# 设计模式

主考双重判断的单例（碰到几次手撸），然后扩展到volatile关键字和synchronize加锁进一步问。

工厂基本没怎么考，偶尔会问了解多少种设计模式。

java容器使用了什么设计模式？（字节跳动）。


# 应用方向与其它

## 设计一个秒杀系统

相关的性能问题可以参考思路。

流量到了亿级别，常见站点架构如上：

1）浏览器端，最上层，会执行到一些JS代码

通过js代码限制秒杀按钮的重复点击（如点击一次后禁止点击、多少秒内重新点击不会提交数据等）

并且提示用户进行频繁刷新等操作对抢购没有帮助等。

2）web端

前面通过按钮能够拦截一般用户的访问请求，但是对开多个浏览器、多个页面、代码直接直接请求等方式无法避免。

在站点层对访问要求，可以针对uid一类的信息做限制。

通过nginx对流量做转发，送到多台服务器。

对于网页中的静态资源构建缓存，通过CDN一类的方式分流。

3）后端

通过前面的两层，可以过滤掉大部分异常的用户请求。针对正常的用户请求重点通过后端来处理。

通过消息队列和异步处理的方式，保证后端系统不用直接处理大量的流量。秒杀的后端访问有读多写少的特点，因此可以考虑用redis做读写的平台，避免数据库的性能瓶颈。

在库存不够时对队列里的写请求返回“已售完”。
